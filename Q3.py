# -*- coding: utf-8 -*-
"""Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hzgXHnZKnqbMCn522LEvd6Xv2Eq9rsJq
"""

import numpy as np
import pandas as pd

df1=pd.read_csv('/22bba507-efcf-4af0-b9d0-f26193605457_train.csv')

df2=pd.read_csv('/3adc8d2b-4db8-4d95-a013-6a8dea863fb0_test.csv')



import sys
import os
import requests
import subprocess
import shutil
from logging import getLogger, StreamHandler, INFO


logger = getLogger(__name__)
logger.addHandler(StreamHandler())
logger.setLevel(INFO)


def install(
        chunk_size=4096,
        file_name="Miniconda3-latest-Linux-x86_64.sh",
        url_base="https://repo.continuum.io/miniconda/",
        conda_path=os.path.expanduser(os.path.join("~", "miniconda")),
        rdkit_version=None,
        add_python_path=True,
        force=False):
    """install rdkit from miniconda
    ```
    import rdkit_installer
    rdkit_installer.install()
    ```
    """

    python_path = os.path.join(
        conda_path,
        "lib",
        "python{0}.{1}".format(*sys.version_info),
        "site-packages",
    )

    if add_python_path and python_path not in sys.path:
        logger.info("add {} to PYTHONPATH".format(python_path))
        sys.path.append(python_path)

    if os.path.isdir(os.path.join(python_path, "rdkit")):
        logger.info("rdkit is already installed")
        if not force:
            return

        logger.info("force re-install")

    url = url_base + file_name
    python_version = "{0}.{1}.{2}".format(*sys.version_info)

    logger.info("python version: {}".format(python_version))

    if os.path.isdir(conda_path):
        logger.warning("remove current miniconda")
        shutil.rmtree(conda_path)
    elif os.path.isfile(conda_path):
        logger.warning("remove {}".format(conda_path))
        os.remove(conda_path)

    logger.info('fetching installer from {}'.format(url))
    res = requests.get(url, stream=True)
    res.raise_for_status()
    with open(file_name, 'wb') as f:
        for chunk in res.iter_content(chunk_size):
            f.write(chunk)
    logger.info('done')

    logger.info('installing miniconda to {}'.format(conda_path))
    subprocess.check_call(["bash", file_name, "-b", "-p", conda_path])
    logger.info('done')

    logger.info("installing rdkit")
    subprocess.check_call([
        os.path.join(conda_path, "bin", "conda"),
        "install",
        "--yes",
        "-c", "rdkit",
        "python=={}".format(python_version),
        "rdkit" if rdkit_version is None else "rdkit=={}".format(rdkit_version)])
    logger.info("done")

    import rdkit
    logger.info("rdkit-{} installation finished!".format(rdkit.__version__))


if __name__ == "__main__":
    install()

!pip install git+https://github.com/samoturk/mol2vec;

labels = df1['Binding Affinity']
df1.drop(columns='Binding Affinity',inplace=True)

from rdkit import Chem 

#Transforming SMILES to MOL
df1['mol'] = df1['SMILES sequence'].apply(lambda x: Chem.MolFromSmiles(x))

from google.colab import drive
drive.mount('/content/drive')

from gensim.models import word2vec
model = word2vec.Word2Vec.load('/content/drive/My Drive/model_300dim.pkl')

from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec
from gensim.models import word2vec
print('Molecular sentence:', mol2alt_sentence(df1['mol'][1], radius=1))
print('\nMolSentence object:', MolSentence(mol2alt_sentence(df1['mol'][1], radius=1)))
print('\nDfVec object:',DfVec(sentences2vec(MolSentence(mol2alt_sentence(df1['mol'][1], radius=1)), model, unseen='UNK')))

#Constructing sentences
df1['sentence']=df1.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)

#Extracting embeddings to a numpy.array
#Note that we always should mark unseen='UNK' in sentence2vec() so that model is taught how to handle unknown substructures
df1['mol2vec'] = [DfVec(x) for x in sentences2vec(df1['sentence'], model, unseen='UNK')]
entire_train_data= np.array([x.vec for x in df1['mol2vec']])
entire_train_labels= labels.values

entire_train_data.shape

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error

X_train, X_test, y_train, y_test = train_test_split(entire_train_data,entire_train_labels, test_size=.2, random_state=1)

from sklearn import svm
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.metrics import mean_absolute_error

C=[0.001,0.01,0.1,1,10,100,500]
rmses=[]
maes=[]
for c in C:
  clf = svm.SVR(C=c)
  clf.fit(X_train, y_train)
  predictions=clf.predict(X_test)
  rmses.append(sqrt(mean_squared_error(y_test,predictions)))
  maes.append(mean_absolute_error(y_test,predictions))



rmses

maes

df2['mol'] = df2['SMILES sequence'].apply(lambda x: Chem.MolFromSmiles(x))
from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec
from gensim.models import word2vec
print('Molecular sentence:', mol2alt_sentence(df2['mol'][1], radius=1))
print('\nMolSentence object:', MolSentence(mol2alt_sentence(df2['mol'][1], radius=1)))
print('\nDfVec object:',DfVec(sentences2vec(MolSentence(mol2alt_sentence(df2['mol'][1], radius=1)), model, unseen='UNK')))
df2['sentence']=df2.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)

#Extracting embeddings to a numpy.array
#Note that we always should mark unseen='UNK' in sentence2vec() so that model is taught how to handle unknown substructures
df2['mol2vec'] = [DfVec(x) for x in sentences2vec(df2['sentence'], model, unseen='UNK')]
test_data= np.array([x.vec for x in df2['mol2vec']])


test_data.shape

clf = svm.SVR(C=100)
clf.fit(entire_train_data,entire_train_labels)
predictions=clf.predict(test_data)



df2.drop(columns='mol',inplace=True)
df2.drop(columns='sentence',inplace=True)
df2.drop(columns='mol2vec',inplace=True)


df2['Binding Affinity']=predictions

df2

output=pd.DataFrame(df2)
output.to_csv('submission.csv',index=False)
from google.colab import files

files.download('submission.csv')

df3=pd.read_csv('/4b566bb4-3155-49ff-91e1-19942504b20c_test.csv')

print(df3.shape)

df3['mol'] = df3['SMILES sequence'].apply(lambda x: Chem.MolFromSmiles(x))
from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec
from gensim.models import word2vec
print('Molecular sentence:', mol2alt_sentence(df3['mol'][1], radius=1))
print('\nMolSentence object:', MolSentence(mol2alt_sentence(df3['mol'][1], radius=1)))
print('\nDfVec object:',DfVec(sentences2vec(MolSentence(mol2alt_sentence(df3['mol'][1], radius=1)), model, unseen='UNK')))
df3['sentence']=df3.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)

#Extracting embeddings to a numpy.array
#Note that we always should mark unseen='UNK' in sentence2vec() so that model is taught how to handle unknown substructures
df3['mol2vec'] = [DfVec(x) for x in sentences2vec(df3['sentence'], model, unseen='UNK')]
final_test_data= np.array([x.vec for x in df3['mol2vec']])


final_test_data.shape


clf = svm.SVR(C=65)
clf.fit(entire_train_data,entire_train_labels)
predictions1=clf.predict(final_test_data)

df3.drop(columns='mol',inplace=True)
df3.drop(columns='sentence',inplace=True)
df3.drop(columns='mol2vec',inplace=True)


df3['Binding Affinity']=predictions1

df3

output=pd.DataFrame(df3)
output.to_csv('final_submission.csv',index=False)
from google.colab import files

files.download('final_submission.csv')

